{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0g5OwWRSi1a",
        "outputId": "cedcf708-2049-4aa0-81f4-060f7c49929a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gt7mF5cSi1b",
        "outputId": "767c1ec1-fb9c-454a-a9f2-03baa19d846d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"daily_dialog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bzTOT7jSi1b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from dataclasses import dataclass\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubZPRImdSi1c"
      },
      "outputs": [],
      "source": [
        "%pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R6JGwnFSi1c"
      },
      "outputs": [],
      "source": [
        "dialogT=[]\n",
        "emotionT=[]\n",
        "dialogV=[]\n",
        "emotionV=[]\n",
        "\n",
        "for i in dataset['train']['dialog']:\n",
        "    for s in i:\n",
        "        dialogT.append(s+'\\n')\n",
        "\n",
        "for i in dataset['train']['emotion']:\n",
        "    for e in i:\n",
        "        emotionT.append(e)\n",
        "\n",
        "for i in dataset['validation']['dialog']:\n",
        "    for s in i:\n",
        "        dialogV.append(s+'\\n')\n",
        "\n",
        "for i in dataset['validation']['emotion']:\n",
        "    for e in i:\n",
        "        emotionV.append(e)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0hHczj1Si1c",
        "outputId": "f405c796-6b11-45b1-93fb-626882375177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "train_ids=[]\n",
        "train_emo_ids=[]\n",
        "val_ids=[]\n",
        "val_emo_ids=[]\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(dialogT)):\n",
        "    ec = enc.encode_ordinary(dialogT[i])\n",
        "    l = len(ec)\n",
        "    train_ids.extend(ec)\n",
        "    train_emo_ids.extend([emotionT[i]]*l)\n",
        "\n",
        "for i in range(len(dialogV)):\n",
        "    ec = enc.encode_ordinary(dialogV[i])\n",
        "    l = len(ec)\n",
        "    val_ids.extend(ec)\n",
        "    val_emo_ids.extend([emotionV[i]]*l)\n",
        "\n",
        "\n",
        "print(len(train_ids))\n",
        "print(train_emo_ids)\n",
        "print(len(train_emo_ids))\n",
        "print(train_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7rluF5hSi1c",
        "outputId": "65a7cf0a-c02e-48a6-db16-6d0398ba8ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[25515   837  5395 ...   764   220   198]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "data_dir = 'friends_gpt2'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# export to bin files\n",
        "train_ids = np.array(train_ids, dtype=np.uint16)\n",
        "val_ids = np.array(val_ids, dtype=np.uint16)\n",
        "train_ids.tofile(os.path.join(data_dir, 'train.bin'))\n",
        "val_ids.tofile(os.path.join(data_dir, 'val.bin'))\n",
        "\n",
        "train_emo_ids=np.array(train_emo_ids, dtype=np.uint16)\n",
        "val_emo_ids = np.array(val_emo_ids, dtype=np.uint16)\n",
        "train_emo_ids.tofile(os.path.join(data_dir, 'train_emo.bin'))\n",
        "val_emo_ids.tofile(os.path.join(data_dir, 'val_emo.bin'))\n",
        "\n",
        "# create a memory map\n",
        "train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
        "val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')\n",
        "\n",
        "train_emo_data = np.memmap(os.path.join(data_dir, 'train_emo.bin'), dtype=np.uint16, mode='r')\n",
        "val_emo_data = np.memmap(os.path.join(data_dir, 'val_emo.bin'), dtype=np.uint16, mode='r')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlEH91KBSi1i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_batch(data, emo, block_size, batch_size, device):\n",
        "    \"\"\"\n",
        "    Return a minibatch of data. This function is not deterministic.\n",
        "    Calling this function multiple times will result in multiple different\n",
        "    return values.\n",
        "\n",
        "    Parameters:\n",
        "        `data` - a numpy array (e.g., created via a call to np.memmap)\n",
        "        `block_size` - the length of each sequence\n",
        "        `batch_size` - the number of sequences in the batch\n",
        "        `device` - the device to place the returned PyTorch tensor\n",
        "\n",
        "    Returns: A tuple of PyTorch tensors (x, t), where\n",
        "        `x` - represents the input tokens, with shape (batch_size, block_size)\n",
        "        `y` - represents the target output tokens, with shape (batch_size, block_size)\n",
        "    \"\"\"\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    e = torch.stack([torch.from_numpy((emo[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    t = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    if 'cuda' in device:\n",
        "        # pin arrays x,t, which allows us to move them to GPU asynchronously\n",
        "        #  (non_blocking=True)\n",
        "        x, t = x.pin_memory().to(device, non_blocking=True), t.pin_memory().to(device, non_blocking=True)\n",
        "        e = e.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, t = x.to(device), t.to(device)\n",
        "        e = e.to(device)\n",
        "    return x, e, t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qSx2aWOSi1j"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqnhGlBMSi1j"
      },
      "outputs": [],
      "source": [
        "def enc_emo(emo):\n",
        "    out = []\n",
        "    for e in emo:\n",
        "        if e == 'no emotion':\n",
        "            out.append(0)\n",
        "        if e == 'anger':\n",
        "            out.append(1)\n",
        "        if e == 'disgust':\n",
        "            out.append(2)\n",
        "        if e == 'fear':\n",
        "            out.append(3)\n",
        "        if e == \"happiness\":\n",
        "            out.append(4)\n",
        "        if e== \"sadness\":\n",
        "            out.append(5)\n",
        "        if e== \"surprise\":\n",
        "            out.append(6)\n",
        "    return out\n",
        "\n",
        "def input_emo_encoder(s, txt_enc):\n",
        "    s = [s]\n",
        "    tmp = enc_emo(s)\n",
        "    out = tmp*len(txt_enc)\n",
        "    return (torch.tensor(out, dtype=torch.long, device=device)[None, ...])\n",
        "\n",
        "\n",
        "def add_emo_helper(emo_idx):\n",
        "    l=len(emo_idx[0])+1\n",
        "    e = emo_idx[0,0]\n",
        "    emotion=''\n",
        "    if e == 0:\n",
        "        emotion='no emotion'\n",
        "    if e == 1:\n",
        "        emotion='anger'\n",
        "    if e == 2:\n",
        "        emotion='disgust'\n",
        "    if e == 3:\n",
        "        emotion='fear'\n",
        "    if e == 4:\n",
        "        emotion='happiness'\n",
        "    if e== 5:\n",
        "        emotion='sadness'\n",
        "    if e== 6:\n",
        "        emotion='surprise'\n",
        "    return input_emo_encoder(emotion, [1]*l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ubGO1QOSi1j"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            wee = nn.Embedding(8, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        # with weight tying when using torch.compile() some warnings get generated:\n",
        "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
        "        # This behavior is deprecated and will be an error in future versions\"\n",
        "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
        "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
        "\n",
        "        # init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        \"\"\"\n",
        "        Return the number of parameters in the model.\n",
        "        For non-embedding count (default), the position embeddings get subtracted.\n",
        "        The token embeddings would too, except due to the parameter sharing these\n",
        "        params are actually used as weights in the final layer, so we include them.\n",
        "        \"\"\"\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, emo_idx,targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
        "        #TODO\n",
        "        emo_emb=self.transformer.wee(emo_idx)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb + emo_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # if we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def crop_block_size(self, block_size):\n",
        "        # model surgery to decrease the block size if necessary\n",
        "        # e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
        "        # but want to use a smaller block size for some smaller, simpler model\n",
        "        assert block_size <= self.config.block_size\n",
        "        self.config.block_size = block_size\n",
        "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
        "        for block in self.transformer.h:\n",
        "            if hasattr(block.attn, 'bias'):\n",
        "                block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type, override_args=None):\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        override_args = override_args or {} # default to empty dict\n",
        "        # only dropout can be overridden see more notes below\n",
        "        assert all(k == 'dropout' for k in override_args)\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # n_layer, n_head and n_embd are determined from model_type\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
        "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
        "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
        "        config_args['bias'] = True # always True for GPT model checkpoints\n",
        "        # we can override the dropout rate, if desired\n",
        "        if 'dropout' in override_args:\n",
        "            print(f\"overriding dropout rate to {override_args['dropout']}\")\n",
        "            config_args['dropout'] = override_args['dropout']\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = GPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
        "        # this means that we have to transpose these weights when we import them\n",
        "        #assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                # special treatment for the Conv1D weights we need to transpose\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                # vanilla copy over the other parameters\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
        "        # start with all of the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == 'cuda'\n",
        "        extra_args = dict(fused=True) if use_fused else dict()\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
        "        \"\"\" estimate model flops utilization (MFU) in units of A100 bfloat16 peak FLOPS \"\"\"\n",
        "        # first estimate the number of flops we do per iteration.\n",
        "        # see PaLM paper Appendix B as ref: https://arxiv.org/abs/2204.02311\n",
        "        N = self.get_num_params()\n",
        "        cfg = self.config\n",
        "        L, H, Q, T = cfg.n_layer, cfg.n_head, cfg.n_embd//cfg.n_head, cfg.block_size\n",
        "        flops_per_token = 6*N + 12*L*H*Q*T\n",
        "        flops_per_fwdbwd = flops_per_token * T\n",
        "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
        "        # express our flops throughput as ratio of A100 bfloat16 peak flops\n",
        "        flops_achieved = flops_per_iter * (1.0/dt) # per second\n",
        "        flops_promised = 312e12 # A100 GPU bfloat16 peak flops is 312 TFLOPS\n",
        "        mfu = flops_achieved / flops_promised\n",
        "        return mfu\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, emo_idx,max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
        "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
        "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # if the sequence context is growing too long we must crop it at block_size\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            if _==0:\n",
        "                emo_cond=emo_idx\n",
        "            if len(emo_cond[0]) < self.config.block_size and _!=0:\n",
        "\n",
        "                emo_cond = add_emo_helper(emo_cond)\n",
        "            else:\n",
        "                emo_idx[:, -self.config.block_size:]\n",
        "\n",
        "            # forward the model to get the logits for the index in the sequence\n",
        "            logits, _ = self(idx_cond, emo_cond)\n",
        "            # pluck the logits at the final step and scale by desired temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            # optionally crop the logits to only the top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            # apply softmax to convert logits to (normalized) probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFpvR2DtSi1j"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
        "\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84pnc31-Si1k"
      },
      "outputs": [],
      "source": [
        "import easydict\n",
        "import math\n",
        "import time\n",
        "\n",
        "finetune_config_dict = {\n",
        "  'gradient_accumulation_steps': 32,\n",
        "  'block_size': 256,\n",
        "  'dropout': 0.2,\n",
        "  'bias': False,\n",
        "  'learning_rate': 3e-5,\n",
        "  'weight_decay': 0.1,\n",
        "  'beta1': 0.9,\n",
        "  'beta2': 0.99,\n",
        "  'grad_clip': 1.0,\n",
        "  'decay_lr': False,\n",
        "  'warmup_iters': 100,\n",
        "  'lr_decay_iters': 5000,\n",
        "  'min_lr': 0.0001}\n",
        "config = easydict.EasyDict(finetune_config_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GgRmpfMSi1k",
        "outputId": "92e6e260-636e-4a33-8219-c997257974ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668,
          "referenced_widgets": [
            "0d28c2be3be440369896f6a6833effc8",
            "57897c18d9ac433e9952ac9435a273f1",
            "78ea2735a8a44a8d8aaed5a7cb5f93f5",
            "c5896e1d58c24088aaf39a19d9ed28d7",
            "ae8a37d495b94e51913d50136d9984ca",
            "e7a6dd6616094f0aa7330262feec2771",
            "0ec6deeb509a47feb486f38a33a04937",
            "b2bbbc9d05434c928574de20e56026b3",
            "722756905fa149aea2da642052e630f4",
            "5388a7ddd8964a0490ddf8175918687c",
            "b5d13564055c43f7a8e267842612898f",
            "9b1c8ccac3f04307b9d7587eec5b7373",
            "ff253d52ee354a3098d9d43418735038",
            "ad5db893ff954d06a8362fdbf5d2c74e",
            "0d82a880321d4af6be3a21da6669666c",
            "91e73ec8c9c54b588ffdab77edb3b43c",
            "b5afed84ace84e4c8b0caf79b62f07c7",
            "7903f91b370d4ffbb38c31f9482afb7e",
            "091448e47eca4138b450b359db020574",
            "8ca23c5b51764ef7a3296fe33695adcb",
            "18c6aefe3ffb4509a967ab5c36694afa",
            "48a3f1ef4cee4b2d998850b9d46b0895",
            "6831af991f644849b0cc4d8e01a2f1f1",
            "ae6dba01553c4e5ea07bd3476278cd24",
            "933c5efa45c5410e8eb45bd99a7889fc",
            "dbc6f9a18e6244afa0257617283db2cb",
            "af54237dfd10456382f426ef316b2643",
            "e62e0f13b8ee41bf99bb608d8b4475c8",
            "c03b6287b1dd48e9ab3f687c4b1efe07",
            "46e0369bf57b4994a599c9b7fbffcd48",
            "5c9643d5891d499db4daebc76278d19f",
            "c264fd995fdc4aa2910568c0f2e8d219",
            "c9c134ca3b27491e91eee7910fe40bfa"
          ]
        },
        "id": "tw6avEvoSi1k",
        "outputId": "b0250feb-9277-47f6-aa45-c7c58c2b74cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights from pretrained gpt: gpt2\n",
            "forcing vocab_size=50257, block_size=1024, bias=True\n",
            "overriding dropout rate to 0.2\n",
            "number of parameters: 123.66M\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d28c2be3be440369896f6a6833effc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b1c8ccac3f04307b9d7587eec5b7373"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6831af991f644849b0cc4d8e01a2f1f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (wee): Embedding(8, 768)\n",
              "    (drop): Dropout(p=0.2, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (ln_1): LayerNorm()\n",
              "        (attn): CausalSelfAttention(\n",
              "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm()\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): GELU(approximate='none')\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# initialize from OpenAI GPT-2 weights\n",
        "override_args = dict(dropout=config.dropout)\n",
        "model = GPT.from_pretrained('gpt2', override_args)\n",
        "\n",
        "# crop down the model block size using model surgery\n",
        "if config.block_size < model.config.block_size:\n",
        "    model.crop_block_size(config.block_size)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available()  else 'cpu'\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri2mzLDySi1k"
      },
      "outputs": [],
      "source": [
        "import contextlib\n",
        "# initialize a GradScaler. If enabled=False scaler is a no-op\n",
        "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "ctx = contextlib.nullcontext() if device == 'cpu' else torch.amp.autocast(device_type=device, dtype=ptdtype)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
        "\n",
        "# learning rate decay scheduler (cosine with warmup)\n",
        "def get_lr(config, it):\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < config.warmup_iters:\n",
        "        return config.learning_rate * it / config.warmup_iters\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > config.lr_decay_iters:\n",
        "        return config.min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - config.warmup_iters) / (config.lr_decay_iters - config.warmup_iters)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
        "    return config.min_lr + coeff * (config.learning_rate - config.min_lr)\n",
        "\n",
        "# helps estimate an arbitrarily accurate loss over either split using many batches\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, train_dataset, emo,val_dataset, block_size):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        dataset = train_dataset if split == 'train' else val_dataset\n",
        "        for k in range(eval_iters):\n",
        "            X, E, Y = get_batch(dataset, emo, block_size, batch_size, device)\n",
        "            with ctx:\n",
        "                logits, loss = model(X, E, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF4QqKkQSi1k"
      },
      "outputs": [],
      "source": [
        "import contextlib\n",
        "# initialize a GradScaler. If enabled=False scaler is a no-op\n",
        "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "ctx = contextlib.nullcontext() if device == 'cpu' else torch.amp.autocast(device_type=device, dtype=ptdtype)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
        "\n",
        "# learning rate decay scheduler (cosine with warmup)\n",
        "def get_lr(config, it):\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < config.warmup_iters:\n",
        "        return config.learning_rate * it / config.warmup_iters\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > config.lr_decay_iters:\n",
        "        return config.min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - config.warmup_iters) / (config.lr_decay_iters - config.warmup_iters)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
        "    return config.min_lr + coeff * (config.learning_rate - config.min_lr)\n",
        "\n",
        "# helps estimate an arbitrarily accurate loss over either split using many batches\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, train_dataset, emo,val_dataset, block_size):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        dataset = train_dataset if split == 'train' else val_dataset\n",
        "        for k in range(eval_iters):\n",
        "            X, E, Y = get_batch(dataset, emo, block_size, batch_size, device)\n",
        "            with ctx:\n",
        "                logits, loss = model(X, E, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZG3ZRo5bxlr",
        "outputId": "33673c69-b64a-4862-a418-cc1c6c3d6df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9wJix1d5Si1l",
        "outputId": "1320124d-4899-4948-d14f-46971c4b1f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num decayed parameter tensors: 51, with 123,734,784 parameters\n",
            "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 3.2750, val loss 3.2594\n",
            "iter 0: loss 4.5529, time 33264.29ms, mfu -100.00%\n",
            "step 10: train loss 2.9487, val loss 2.9481\n",
            "iter 10: loss 3.3746, time 33480.50ms, mfu 2.11%\n",
            "step 20: train loss 2.8062, val loss 2.8047\n",
            "iter 20: loss 3.1046, time 33493.26ms, mfu 2.11%\n",
            "step 30: train loss 2.7352, val loss 2.7401\n",
            "iter 30: loss 3.0904, time 33455.46ms, mfu 2.11%\n",
            "step 40: train loss 2.6855, val loss 2.7048\n",
            "iter 40: loss 2.9044, time 33513.05ms, mfu 2.11%\n",
            "step 50: train loss 2.6628, val loss 2.6636\n",
            "iter 50: loss 2.8909, time 33520.41ms, mfu 2.11%\n",
            "step 60: train loss 2.6334, val loss 2.6651\n",
            "iter 60: loss 2.8650, time 33542.73ms, mfu 2.11%\n",
            "step 70: train loss 2.6133, val loss 2.6358\n",
            "iter 70: loss 2.8025, time 33512.05ms, mfu 2.11%\n",
            "step 80: train loss 2.5940, val loss 2.6036\n",
            "iter 80: loss 2.8226, time 33565.12ms, mfu 2.11%\n",
            "step 90: train loss 2.5836, val loss 2.5998\n",
            "iter 90: loss 2.6890, time 33521.59ms, mfu 2.11%\n",
            "step 100: train loss 2.5572, val loss 2.5977\n",
            "iter 100: loss 2.8003, time 33492.64ms, mfu 2.11%\n",
            "step 110: train loss 2.5420, val loss 2.5791\n",
            "iter 110: loss 2.7870, time 33551.78ms, mfu 2.11%\n",
            "step 120: train loss 2.5361, val loss 2.5761\n",
            "iter 120: loss 2.6591, time 33493.58ms, mfu 2.11%\n",
            "step 130: train loss 2.5122, val loss 2.5613\n",
            "iter 130: loss 2.7113, time 33453.94ms, mfu 2.11%\n",
            "step 140: train loss 2.5118, val loss 2.5406\n",
            "iter 140: loss 2.7237, time 33494.12ms, mfu 2.11%\n",
            "step 150: train loss 2.4825, val loss 2.5577\n",
            "iter 150: loss 2.6447, time 33454.68ms, mfu 2.11%\n",
            "step 160: train loss 2.4743, val loss 2.5487\n",
            "iter 160: loss 2.6563, time 33529.74ms, mfu 2.11%\n",
            "step 170: train loss 2.4654, val loss 2.5280\n",
            "iter 170: loss 2.6535, time 33516.93ms, mfu 2.11%\n",
            "step 180: train loss 2.4634, val loss 2.5312\n",
            "iter 180: loss 2.7074, time 33562.18ms, mfu 2.11%\n",
            "step 190: train loss 2.4518, val loss 2.5190\n",
            "iter 190: loss 2.6519, time 33451.35ms, mfu 2.11%\n",
            "step 200: train loss 2.4337, val loss 2.5070\n",
            "iter 200: loss 2.6761, time 33493.14ms, mfu 2.11%\n",
            "step 210: train loss 2.4244, val loss 2.4931\n",
            "iter 210: loss 2.5644, time 33480.87ms, mfu 2.11%\n",
            "step 220: train loss 2.4115, val loss 2.5036\n",
            "iter 220: loss 2.5937, time 33527.63ms, mfu 2.11%\n",
            "step 230: train loss 2.4116, val loss 2.4917\n",
            "iter 230: loss 2.5126, time 33551.39ms, mfu 2.11%\n",
            "step 240: train loss 2.4062, val loss 2.4942\n",
            "iter 240: loss 2.6314, time 33495.11ms, mfu 2.11%\n",
            "step 250: train loss 2.3912, val loss 2.4831\n",
            "iter 250: loss 2.6073, time 33434.80ms, mfu 2.11%\n",
            "step 260: train loss 2.3731, val loss 2.4803\n",
            "iter 260: loss 2.5660, time 33462.92ms, mfu 2.11%\n",
            "step 270: train loss 2.3691, val loss 2.4698\n",
            "iter 270: loss 2.5353, time 33513.60ms, mfu 2.11%\n",
            "step 280: train loss 2.3615, val loss 2.4666\n",
            "iter 280: loss 2.5638, time 33520.16ms, mfu 2.11%\n",
            "step 290: train loss 2.3478, val loss 2.4685\n",
            "iter 290: loss 2.5063, time 33497.20ms, mfu 2.11%\n",
            "step 300: train loss 2.3543, val loss 2.4547\n",
            "iter 300: loss 2.5251, time 33539.67ms, mfu 2.11%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Parent directory C:/Users/c/Desktop does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e80505336e3c>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C:/Users/c/Desktop/chatbot2.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory C:/Users/c/Desktop does not exist."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import gc\n",
        "gc.collect()\n",
        "iter_num = 0\n",
        "best_val_loss = 1e9\n",
        "eval_interval = 10\n",
        "log_interval = 10\n",
        "eval_iters = 40\n",
        "max_iters = 300\n",
        "batch_size = 35\n",
        "\n",
        "# optimizer\n",
        "optimizer = model.configure_optimizers(config.weight_decay, config.learning_rate,\n",
        "   (config.beta1, config.beta2), device)\n",
        "\n",
        "# training loop\n",
        "X, E, Y = get_batch(train_data, train_emo_data, config.block_size, batch_size, device) # fetch the very first batch\n",
        "t0 = time.time()\n",
        "local_iter_num = 0 # number of iterations in the lifetime of this process\n",
        "raw_model = model # unwrap DDP container if needed\n",
        "running_mfu = -1.0\n",
        "try:\n",
        "    iters, train_loss, val_loss= [], [], []\n",
        "    while True:\n",
        "        # determine and set the learning rate for this iteration\n",
        "        lr = get_lr(config, iter_num) if config.decay_lr else config.learning_rate\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        # evaluate the loss on train/val sets and write checkpoints\n",
        "        if iter_num % eval_interval == 0:\n",
        "            losses = estimate_loss(model, train_data, train_emo_data, val_data, config.block_size)\n",
        "            iters.append(iter_num)\n",
        "            train_loss.append(losses['train'])\n",
        "            val_loss.append(losses['val'])\n",
        "            print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "        # forward backward update, with optional gradient accumulation to simulate larger batch size\n",
        "        # and using the GradScaler if data type is float16\n",
        "        for micro_step in range(config.gradient_accumulation_steps):\n",
        "            with ctx:\n",
        "                logits, loss = model(X, E, Y)\n",
        "                loss = loss / config.gradient_accumulation_steps # scale the loss to account for gradient accumulation\n",
        "            # immediately async prefetch next batch while model is doing the forward pass on the GPU\n",
        "            X, E, Y = get_batch(train_data, train_emo_data, config.block_size, batch_size, device)\n",
        "            # backward pass, with gradient scaling if training in fp16\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "        # clip the gradient\n",
        "        if config.grad_clip != 0.0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "\n",
        "        # step the optimizer and scaler if training in fp16\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # flush the gradients as soon as we can, no need for this memory anymore\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # timing and logging\n",
        "        t1 = time.time()\n",
        "        dt = t1 - t0\n",
        "        t0 = t1\n",
        "        if iter_num % log_interval == 0:\n",
        "            # get loss as float. note: this is a CPU-GPU sync point\n",
        "            # scale up to undo the division above, approximating the true total loss (exact would have been a sum)\n",
        "            lossf = loss.item() * config.gradient_accumulation_steps\n",
        "            if local_iter_num >= 5: # let the training loop settle a bit\n",
        "                mfu = raw_model.estimate_mfu(batch_size * config.gradient_accumulation_steps, dt)\n",
        "                running_mfu = mfu if running_mfu == -1.0 else 0.9*running_mfu + 0.1*mfu\n",
        "            print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, mfu {running_mfu*100:.2f}%\")\n",
        "\n",
        "        iter_num += 1\n",
        "        local_iter_num += 1\n",
        "\n",
        "        # termination conditions\n",
        "        if iter_num > max_iters:\n",
        "            break\n",
        "\n",
        "finally:\n",
        "    plt.figure()\n",
        "    plt.plot(iters[:len(train_loss)], train_loss)\n",
        "    plt.plot(iters[:len(val_loss)], val_loss)\n",
        "    plt.title(\"Loss over iterations\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend([\"Train\", \"Validation\"])\n",
        "\n",
        "\n",
        "model.eval()\n",
        "torch.save(copy.deepcopy(model.state_dict()), \"/content/drive/MyDrive/chatbot2.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(copy.deepcopy(model.state_dict()), \"/content/drive/MyDrive/chatbot2.pth\")"
      ],
      "metadata": {
        "id": "RYgR4I3zzLBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff8mForMSi1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b302617f-39e2-486a-aec7-88c231e27ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Yes . I feel very sad about this.Our wedding is to be held on October 24th , so I have to prepare my things . \n",
            " We promise to arrange a reception for December 30th.Will you please come and have a look ? \n",
            " I will . There are so many people I could not attend . \n",
            " Why are you so nervous ? \n",
            " I am afraid that the weather is kind to us . I have a fever . \n",
            " What can I do for you\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/chatbot2.pth\"))\n",
        "model.eval()\n",
        "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
        "out_dir = 'out' # ignored if init_from is not 'resume'\n",
        "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
        "start_emo='happiness'\n",
        "num_samples = 1 # number of samples to draw\n",
        "max_new_tokens = 100 # number of tokens generated in each sample\n",
        "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
        "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
        "\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
        "decode = lambda l: enc.decode(l)\n",
        "\n",
        "start_ids = encode(start)\n",
        "\n",
        "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
        "e = input_emo_encoder(start_emo,start_ids)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#model = finetuned_model\n",
        "# run generation\n",
        "\n",
        "with torch.no_grad():\n",
        "    with ctx:\n",
        "        for k in range(num_samples):\n",
        "            y = model.generate(x, e, max_new_tokens, temperature=temperature, top_k=top_k)\n",
        "            out = decode(y[0].tolist())\n",
        "            print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"I'm so mad right now ! \\n\",\n",
        "    'This makes me angry . \\n',\n",
        "    \"I'm fuming ! \\n\",\n",
        "    'Why am I always so angry ? \\n',\n",
        "    \"I'm outraged ! \\n\",\n",
        "    \"That's gross ! \\n\",\n",
        "    \"I'm disgusted . \\n\",\n",
        "    \"Ew ,  that's nasty ! \\n\",\n",
        "    'This is repulsive . \\n',\n",
        "    \"I can't stand this . \\n\",\n",
        "    \"I'm scared . \\n\",\n",
        "    'This is terrifying . \\n',\n",
        "    'I feel afraid . \\n',\n",
        "    \"I'm really frightened . \\n\",\n",
        "    'This is spooky . \\n',\n",
        "    \"I'm so happy ! \\n\",\n",
        "    'This is awesome ! \\n',\n",
        "    \"I'm delighted . \\n\",\n",
        "    \"Yay ,  I'm so glad ! \\n\",\n",
        "    'This makes me smile . \\n',\n",
        "    \"I'm feeling sad . \\n\",  # Sadness\n",
        "    \"This is so upsetting . \\n\",  # Sadness\n",
        "    \"I'm really down . \\n\",  # Sadness\n",
        "    \"Why am I so sad ? \\n\",  # Sadness\n",
        "    \"This makes me gloomy . \\n\",  # Sadness\n",
        "    \"Wow ,  that's surprising ! \\n\",  # Surprise\n",
        "    \"I didn't expect this . \\n\",  # Surprise\n",
        "    \"This is shocking ! \\n\",  # Surprise\n",
        "    \"Really ?  That's unexpected . \\n\",  # Surprise\n",
        "    \"I'm amazed by this ! \\n\"   # Surprise\n",
        "]\n",
        "test_emo = [\n",
        "    \"anger\",       # For sentences 1-5\n",
        "    \"anger\",\n",
        "    \"anger\",\n",
        "    \"anger\",\n",
        "    \"anger\",\n",
        "    \"disgust\",     # For sentences 6-10\n",
        "    \"disgust\",\n",
        "    \"disgust\",\n",
        "    \"disgust\",\n",
        "    \"disgust\",\n",
        "    \"fear\",        # For sentences 11-15\n",
        "    \"fear\",\n",
        "    \"fear\",\n",
        "    \"fear\",\n",
        "    \"fear\",\n",
        "    \"happiness\",   # For sentences 16-20\n",
        "    \"happiness\",\n",
        "    \"happiness\",\n",
        "    \"happiness\",\n",
        "    \"happiness\",\n",
        "    \"sadness\",     # For sentences 21-25\n",
        "    \"sadness\",\n",
        "    \"sadness\",\n",
        "    \"sadness\",\n",
        "    \"sadness\",\n",
        "    \"surprise\",   # For sentences 26-30\n",
        "    \"surprise\",\n",
        "    \"surprise\",\n",
        "    \"surprise\",\n",
        "    \"surprise\"\n",
        "]\n",
        "\n",
        "out = []\n",
        "for i in range(len(test_sentences)):\n",
        "    start_ids = encode(test_sentences[i])\n",
        "    x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
        "    e = input_emo_encoder(test_emo[i],start_ids)\n",
        "    with torch.no_grad():\n",
        "        with ctx:\n",
        "            for k in range(num_samples):\n",
        "                y = model.generate(x, e, max_new_tokens, temperature=temperature, top_k=top_k)\n",
        "                out.append(decode(y[0].tolist()))\n",
        "\n",
        "outt = []\n",
        "for i in out:\n",
        "    outt.append(i.split(\"\\n\")[1:-1])\n",
        "\n",
        "print(outt)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku62PV08zVLT",
        "outputId": "5322b249-1186-46df-c296-d4b988e03937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[' How dare you do that . ', ' Oh , dear ! What have you done to that ? ', \" No , it's nothing . \", \" Oh , dear , it's nothing ! \", \" Thank you.You'll have a delicious meal later . \", \" I'll go . \", \"You're welcome . See you in a week . \", ' No problem . ', 'Excuse me . I am looking for my passport . ', ' Could you show me your passport please ? '], [\" If it wasn't for you , I wouldn't tell you . \", \" You've got to go . \", \"Have you heard about America's unemployment problem ? \", ' Yes , it has been steadily rising for many years . ', \" I've heard that Americans have a high rate of unemployment . \", ' What does it mean ? ', ' The American dream is to have a job and have a family , but unemployment is not the only responsibility that comes with it . ', ' Really ? '], [' What ? But I have a baby . ', ' My mind is on it . ', ' How can you say that ? ', \" You don't know what you're talking about . I know I've been out of work since 7 , and I ’ m getting laid off.So you're going crazy ? \", \" Yeah , I mean , I'm freaking out . What am I supposed to do ? \"], [\" I always feel terrible , but I've always been bright and energetic . \", \" What's so special about you ? \", ' I want you to be my new teacher . ', \" I'd like to come to school every day . \", 'How are you doing ? ', \" I'm fine . \", ' What are you up to ? ', \" I ’ Ve got a dance and I'm studying physics . \", ' Is that true ? ', ' Yes , I ’ m learning . '], [\" What's wrong with you ? \", ' I was so upset yesterday . ', \" You're such a greedy American . \", \" I'm sorry , but you need to go back to school . \", ' Fine . ', 'Can you tell me how to get there ? ', ' Take the metro . ', ' Is there any highway left ? ', ' No.How about going to the police station at the next stop ? ', \" Why don't you go to the National Bank ? \"], [\" What are you talking about ? It's the most disgusting , disgusting thing I've ever seen in my life ! \", ' Yeah . I think we should clean the room . ', \" I know , but it's really very disgusting at the same time . \", 'Excuse me . What should I do next ? ', ' Will you please take a look at this map ? ', ' Here it is . ', ' It ’ s all over the map . '], [' I know . ', \" I've heard about all kinds of things . I believe in love . \", ' Why are you so angry about it ? ', \" I don't know . \", ' What do you mean ? ', \" I'm not mad . \", 'Are you free on Saturday or Sunday ? ', \" I'll be there tomorrow . \", \" That's perfect . \", \" Let's go . \", 'Excuse me , is this the bus leaving in ten minutes ? '], [\" Well , let me see ... you're a free man ! \", \" Well , let's call it a day . \", \" Good idea . Let's go back and finish this ! \", ' Why ? ', \" It's a holiday , isn't it ? \", ' What time is it ? ', \" It's Saturday . \", \" Ok , let's finish that . \", \" Hey ! Don't do anything silly ! \", 'Hey , Tom , what ’ s up ? '], [\" Yes . It's unbelievable . \", 'Hello , Tom . This is Bill . Good morning . What can I help you ? ', ' Hi , Daniel . I am waiting for a package . ', ' Is there anything I can help you with ? ', ' Yes , what kind of package would you like ? ', ' I have a package for my daughter . ', ' Do you have a package ? ', ' No , I do not . ', \" What's the price , Daniel ? \"], [\" Oh , I can't . \", \" You should stop . You're getting married too soon . \", \" Yes , I can't stand you . \", \" You're a beautiful woman . \", ' I envy you . ', \" I'd better stop . \", 'You ’ re such a grown-up . ', ' I ’ m not , I ’ m just a baby . ', ' But you look so young and strong . '], [\" Don't worry . \", ' Are you sure ? ', \" Yeah . I'm sure . I just really have no idea . \", \" Why don't we have a meeting this afternoon ? \", \" I think it's a good opportunity to talk about the management and work relationship . \", \" OK . Let's take a look at the slides . \", ' Here you go ! What are they about ? ', \" They're a couple of documents making a decision about management . \"], ['Hi , how are you ? ', ' Fine . I ’ m feeling better . ', ' And how are you doing ? ', ' Great . I ’ m feeling better too . I ’ Ve had a little trouble sleeping . ', ' Oh , what a shame ! '], [\" As a matter of fact , I've been feeling quite good lately . \", ' What do you think about it ? ', ' I feel better now . ', \" If something's bothering you , just leave me an email . \", ' Thank you . ', 'Have you noticed how handsome you are ? ', \" Yes , I've seen you in public places . \", \" I'm too small ! \", ' I can wear a lot of clothes . ', \" I think you're smart . \"], [' How long have you been feeling this way ? ', \" I haven't been feeling it for two weeks . I think I'm overreacting . I'm really worried . \", \" I guess you're right . I'm trying to sleep now . \", \" It's a bit difficult . I find it hard to concentrate . \", \" We're trying to make up to you . \", ' I feel awful . ', \"I don't know if we can get on with this . \"], [' Why bother ? ', \" It's not crazy . \", ' I heard the story , Mr . Simpson . He used to work for the newspaper . ', \" Maybe he doesn't tell us anything . \", ' You bet ! ', \" He's very nice to me . \", \" Well , it's time for me to step away . \", \" I don't mind if you wait and see . \", 'Excuse me , would you please come in ? '], [' Thank you for inviting me . ', \" I'll be here in a minute . Can I help you ? \", ' Sure . Here you are . ', \"I'm glad we have found a place to live . \", ' Yes , I have . ', ' Could you come over and have a look ? ', \" Sure , I'd like to . \", ' Where would you like to live ? ', \" I'd like to live in a small apartment . \"], [\" I'll use it on one of the chairs next time . \", 'I am so glad to hear that . ', ' When can I expect you to arrive ? ', ' I am planning to visit your sister in Beijing sometime next month . ', 'May I have the guestbook of your meeting ? ', \" Sir , I am glad to meet you . In the meantime , I'd like to send you an informal invitation . \", ' OK . Please give me a call sometime next week . '], [' OK . Do you want to go with me ? ', \" We'll go next to the club next Thursday . \", ' What time is it ? ', \" We'll be waiting for you then . \", 'Good morning , sir . I ’ m sorry to have brought you this wrong item . ', ' Thank you , sir . I would like to order a hamburger . ', ' Can you give me directions as to where it ’ s located ? '], ['Hi , Mary ! How nice to meet you . ', ' Thanks , Mary . I ’ Ve decided to go to a movie with you . ', ' I ’ Ve seen the movie and I ’ m really excited about it ! ', ' I like the music . I ’ Ve got to go and see it . ', ' Look , I ’ Ve got to go and see it . ', 'Hi , Mary ! When do you come back ? '], [\" You're right . You look beautiful . \", \" Yes . I'm glad to see you again . \", 'May I help you ? ', \" Yes , I'm looking for a room with a view , please . \", ' How long would you like to stay ? ', ' About 5 nights . ', ' Do you have a reservation ? ', ' Yes . ', 'How would you like to go to the library ? ', \" I've got to get to the library at 7 . \"], [\" Yes , I'm feeling depressed . \", ' Did you sleep well yesterday ? ', ' Actually , I feel a lot better today . ', \" Oh , no , I didn't sleep well . \", \" Oh , no , I'm too tired to sleep . \", ' Maybe you should try something else . ', 'Hi , Jill . How are you ? ', ' Great . I feel good . What can I do for you ? ', \" I'm getting ready for vacation . \"], [' I am sorry that you have no choice . ', \" I'm sorry to hear that . \", \" I understand . Here's your apology and I will make it to you by tomorrow afternoon . \", 'Would you like anything else ? ', \" Yes , I'd like a cup of coffee , please . \", ' Please fill in the form . ', \" OK . Let me check if you'd like any special items . \", ' Could I bring a briefcase with you ? '], [\" That's not fair . He put me in a sticky position . \", ' Make up your mind . ', 'Hi , Mary . Nice to meet you . ', ' Hi , Joe . ', ' Hi , Alice . Nice to meet you too . ', ' Nice to meet you too . ', ' Nice to meet you too . ', ' Nice to meet you too . ', ' Nice to meet you too . ', ' OK , Joe . Nice to meet you too . '], [' Well , I totally bought her the hat . ', \" Don't be so negative . You just let go of her . \", 'Have you got any ideas on what kind of action to take ? ', ' I think I ’ ll take some action . ', ' What would you like to do ? ', ' I ’ d like to go to my home . ', ' I ’ m sorry , but it ’ s not taking far . '], [' I ’ m not sure . ', 'I want to buy a motorcycle . ', ' What kind of motorcycle do you want ? ', ' Honda motorcycle . ', ' What kind of motorcycle do you want ? ', ' I want to have a motorcycle . ', ' What kind of motorcycle must we buy ? ', \" I want to have a motorcycle that suits my needs , so I don't have to worry about it . \", ' What are you looking for ? '], [\" Your age is 42 . Does it matter if I'm younger or younger ? \", \" It's just that I'm very young . \", ' So what did you have to learn ? ', ' I think I learned a lot . I learned to fly . ', ' Really ? Tell me about it . ', ' They used to fly every weekend . ', ' A lot of people have been flying together . ', ' Then how did you learn to fly ? '], [\" You're lucky . \", 'I like to watch sports . ', ' I like to watch football , too . ', ' What sports do you like ? ', ' Basketball and rugby . ', ' How do you like them ? ', ' They are fun . ', \" Don't worry . They don't even have to be played , though . \", \" That's good . \", 'My Santa gave me an amazing bag ! ', ' What a surprise ! ', ' It was my birthday present . '], [' I was on my way to get a table with my family when it was first announced that all of our guests would be getting a part-time job on campus . ', ' How did you know that ? ', ' I thought it was my idea to have lunch with my family . ', ' I think the dinner would be great for our family . ', ' Good idea ! And the whole family would come together to have a great time together ! '], [\" I don't like it . It's too loud , too . \", \"It's freezing outside . \", \" It's getting late . \", \" Don't worry . I'll be back soon . \", \" Thanks , but I've lost my wallet . \", ' You could have picked me up somewhere . ', \" Well , I'm glad you asked . \", \" I'm glad you didn't . \", ' I just remember . ', 'What ’ s wrong with you ? '], ['Hello ! Would you like to help me ? ', ' How may I help you ? ', ' I would like to buy some wool clothes . What kind of clothes should I get ? ', ' What kind of fleece ? ', ' I would like it made of 100 % wool and 100 % cotton . ', \" That's too expensive . Would you give me a ring for this ? \", ' Of course ! ', 'I want to make a diamond ring . ']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in outt:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfDrN_00z8yL",
        "outputId": "032bce94-8479-4914-ed4a-edaa89ce0b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' How dare you do that . ', ' Oh , dear ! What have you done to that ? ', \" No , it's nothing . \", \" Oh , dear , it's nothing ! \", \" Thank you.You'll have a delicious meal later . \", \" I'll go . \", \"You're welcome . See you in a week . \", ' No problem . ', 'Excuse me . I am looking for my passport . ', ' Could you show me your passport please ? ']\n",
            "[\" If it wasn't for you , I wouldn't tell you . \", \" You've got to go . \", \"Have you heard about America's unemployment problem ? \", ' Yes , it has been steadily rising for many years . ', \" I've heard that Americans have a high rate of unemployment . \", ' What does it mean ? ', ' The American dream is to have a job and have a family , but unemployment is not the only responsibility that comes with it . ', ' Really ? ']\n",
            "[' What ? But I have a baby . ', ' My mind is on it . ', ' How can you say that ? ', \" You don't know what you're talking about . I know I've been out of work since 7 , and I ’ m getting laid off.So you're going crazy ? \", \" Yeah , I mean , I'm freaking out . What am I supposed to do ? \"]\n",
            "[\" I always feel terrible , but I've always been bright and energetic . \", \" What's so special about you ? \", ' I want you to be my new teacher . ', \" I'd like to come to school every day . \", 'How are you doing ? ', \" I'm fine . \", ' What are you up to ? ', \" I ’ Ve got a dance and I'm studying physics . \", ' Is that true ? ', ' Yes , I ’ m learning . ']\n",
            "[\" What's wrong with you ? \", ' I was so upset yesterday . ', \" You're such a greedy American . \", \" I'm sorry , but you need to go back to school . \", ' Fine . ', 'Can you tell me how to get there ? ', ' Take the metro . ', ' Is there any highway left ? ', ' No.How about going to the police station at the next stop ? ', \" Why don't you go to the National Bank ? \"]\n",
            "[\" What are you talking about ? It's the most disgusting , disgusting thing I've ever seen in my life ! \", ' Yeah . I think we should clean the room . ', \" I know , but it's really very disgusting at the same time . \", 'Excuse me . What should I do next ? ', ' Will you please take a look at this map ? ', ' Here it is . ', ' It ’ s all over the map . ']\n",
            "[' I know . ', \" I've heard about all kinds of things . I believe in love . \", ' Why are you so angry about it ? ', \" I don't know . \", ' What do you mean ? ', \" I'm not mad . \", 'Are you free on Saturday or Sunday ? ', \" I'll be there tomorrow . \", \" That's perfect . \", \" Let's go . \", 'Excuse me , is this the bus leaving in ten minutes ? ']\n",
            "[\" Well , let me see ... you're a free man ! \", \" Well , let's call it a day . \", \" Good idea . Let's go back and finish this ! \", ' Why ? ', \" It's a holiday , isn't it ? \", ' What time is it ? ', \" It's Saturday . \", \" Ok , let's finish that . \", \" Hey ! Don't do anything silly ! \", 'Hey , Tom , what ’ s up ? ']\n",
            "[\" Yes . It's unbelievable . \", 'Hello , Tom . This is Bill . Good morning . What can I help you ? ', ' Hi , Daniel . I am waiting for a package . ', ' Is there anything I can help you with ? ', ' Yes , what kind of package would you like ? ', ' I have a package for my daughter . ', ' Do you have a package ? ', ' No , I do not . ', \" What's the price , Daniel ? \"]\n",
            "[\" Oh , I can't . \", \" You should stop . You're getting married too soon . \", \" Yes , I can't stand you . \", \" You're a beautiful woman . \", ' I envy you . ', \" I'd better stop . \", 'You ’ re such a grown-up . ', ' I ’ m not , I ’ m just a baby . ', ' But you look so young and strong . ']\n",
            "[\" Don't worry . \", ' Are you sure ? ', \" Yeah . I'm sure . I just really have no idea . \", \" Why don't we have a meeting this afternoon ? \", \" I think it's a good opportunity to talk about the management and work relationship . \", \" OK . Let's take a look at the slides . \", ' Here you go ! What are they about ? ', \" They're a couple of documents making a decision about management . \"]\n",
            "['Hi , how are you ? ', ' Fine . I ’ m feeling better . ', ' And how are you doing ? ', ' Great . I ’ m feeling better too . I ’ Ve had a little trouble sleeping . ', ' Oh , what a shame ! ']\n",
            "[\" As a matter of fact , I've been feeling quite good lately . \", ' What do you think about it ? ', ' I feel better now . ', \" If something's bothering you , just leave me an email . \", ' Thank you . ', 'Have you noticed how handsome you are ? ', \" Yes , I've seen you in public places . \", \" I'm too small ! \", ' I can wear a lot of clothes . ', \" I think you're smart . \"]\n",
            "[' How long have you been feeling this way ? ', \" I haven't been feeling it for two weeks . I think I'm overreacting . I'm really worried . \", \" I guess you're right . I'm trying to sleep now . \", \" It's a bit difficult . I find it hard to concentrate . \", \" We're trying to make up to you . \", ' I feel awful . ', \"I don't know if we can get on with this . \"]\n",
            "[' Why bother ? ', \" It's not crazy . \", ' I heard the story , Mr . Simpson . He used to work for the newspaper . ', \" Maybe he doesn't tell us anything . \", ' You bet ! ', \" He's very nice to me . \", \" Well , it's time for me to step away . \", \" I don't mind if you wait and see . \", 'Excuse me , would you please come in ? ']\n",
            "[' Thank you for inviting me . ', \" I'll be here in a minute . Can I help you ? \", ' Sure . Here you are . ', \"I'm glad we have found a place to live . \", ' Yes , I have . ', ' Could you come over and have a look ? ', \" Sure , I'd like to . \", ' Where would you like to live ? ', \" I'd like to live in a small apartment . \"]\n",
            "[\" I'll use it on one of the chairs next time . \", 'I am so glad to hear that . ', ' When can I expect you to arrive ? ', ' I am planning to visit your sister in Beijing sometime next month . ', 'May I have the guestbook of your meeting ? ', \" Sir , I am glad to meet you . In the meantime , I'd like to send you an informal invitation . \", ' OK . Please give me a call sometime next week . ']\n",
            "[' OK . Do you want to go with me ? ', \" We'll go next to the club next Thursday . \", ' What time is it ? ', \" We'll be waiting for you then . \", 'Good morning , sir . I ’ m sorry to have brought you this wrong item . ', ' Thank you , sir . I would like to order a hamburger . ', ' Can you give me directions as to where it ’ s located ? ']\n",
            "['Hi , Mary ! How nice to meet you . ', ' Thanks , Mary . I ’ Ve decided to go to a movie with you . ', ' I ’ Ve seen the movie and I ’ m really excited about it ! ', ' I like the music . I ’ Ve got to go and see it . ', ' Look , I ’ Ve got to go and see it . ', 'Hi , Mary ! When do you come back ? ']\n",
            "[\" You're right . You look beautiful . \", \" Yes . I'm glad to see you again . \", 'May I help you ? ', \" Yes , I'm looking for a room with a view , please . \", ' How long would you like to stay ? ', ' About 5 nights . ', ' Do you have a reservation ? ', ' Yes . ', 'How would you like to go to the library ? ', \" I've got to get to the library at 7 . \"]\n",
            "[\" Yes , I'm feeling depressed . \", ' Did you sleep well yesterday ? ', ' Actually , I feel a lot better today . ', \" Oh , no , I didn't sleep well . \", \" Oh , no , I'm too tired to sleep . \", ' Maybe you should try something else . ', 'Hi , Jill . How are you ? ', ' Great . I feel good . What can I do for you ? ', \" I'm getting ready for vacation . \"]\n",
            "[' I am sorry that you have no choice . ', \" I'm sorry to hear that . \", \" I understand . Here's your apology and I will make it to you by tomorrow afternoon . \", 'Would you like anything else ? ', \" Yes , I'd like a cup of coffee , please . \", ' Please fill in the form . ', \" OK . Let me check if you'd like any special items . \", ' Could I bring a briefcase with you ? ']\n",
            "[\" That's not fair . He put me in a sticky position . \", ' Make up your mind . ', 'Hi , Mary . Nice to meet you . ', ' Hi , Joe . ', ' Hi , Alice . Nice to meet you too . ', ' Nice to meet you too . ', ' Nice to meet you too . ', ' Nice to meet you too . ', ' Nice to meet you too . ', ' OK , Joe . Nice to meet you too . ']\n",
            "[' Well , I totally bought her the hat . ', \" Don't be so negative . You just let go of her . \", 'Have you got any ideas on what kind of action to take ? ', ' I think I ’ ll take some action . ', ' What would you like to do ? ', ' I ’ d like to go to my home . ', ' I ’ m sorry , but it ’ s not taking far . ']\n",
            "[' I ’ m not sure . ', 'I want to buy a motorcycle . ', ' What kind of motorcycle do you want ? ', ' Honda motorcycle . ', ' What kind of motorcycle do you want ? ', ' I want to have a motorcycle . ', ' What kind of motorcycle must we buy ? ', \" I want to have a motorcycle that suits my needs , so I don't have to worry about it . \", ' What are you looking for ? ']\n",
            "[\" Your age is 42 . Does it matter if I'm younger or younger ? \", \" It's just that I'm very young . \", ' So what did you have to learn ? ', ' I think I learned a lot . I learned to fly . ', ' Really ? Tell me about it . ', ' They used to fly every weekend . ', ' A lot of people have been flying together . ', ' Then how did you learn to fly ? ']\n",
            "[\" You're lucky . \", 'I like to watch sports . ', ' I like to watch football , too . ', ' What sports do you like ? ', ' Basketball and rugby . ', ' How do you like them ? ', ' They are fun . ', \" Don't worry . They don't even have to be played , though . \", \" That's good . \", 'My Santa gave me an amazing bag ! ', ' What a surprise ! ', ' It was my birthday present . ']\n",
            "[' I was on my way to get a table with my family when it was first announced that all of our guests would be getting a part-time job on campus . ', ' How did you know that ? ', ' I thought it was my idea to have lunch with my family . ', ' I think the dinner would be great for our family . ', ' Good idea ! And the whole family would come together to have a great time together ! ']\n",
            "[\" I don't like it . It's too loud , too . \", \"It's freezing outside . \", \" It's getting late . \", \" Don't worry . I'll be back soon . \", \" Thanks , but I've lost my wallet . \", ' You could have picked me up somewhere . ', \" Well , I'm glad you asked . \", \" I'm glad you didn't . \", ' I just remember . ', 'What ’ s wrong with you ? ']\n",
            "['Hello ! Would you like to help me ? ', ' How may I help you ? ', ' I would like to buy some wool clothes . What kind of clothes should I get ? ', ' What kind of fleece ? ', ' I would like it made of 100 % wool and 100 % cotton . ', \" That's too expensive . Would you give me a ring for this ? \", ' Of course ! ', 'I want to make a diamond ring . ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in out:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzPqyhVpzfX-",
        "outputId": "e052c69e-b77f-4d97-f648-b2e39b81262f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm so mad right now ! \n",
            " How dare you do that . \n",
            " Oh , dear ! What have you done to that ? \n",
            " No , it's nothing . \n",
            " Oh , dear , it's nothing ! \n",
            " Thank you.You'll have a delicious meal later . \n",
            " I'll go . \n",
            "You're welcome . See you in a week . \n",
            " No problem . \n",
            "Excuse me . I am looking for my passport . \n",
            " Could you show me your passport please ? \n",
            " Sorry.\n",
            "This makes me angry . \n",
            " If it wasn't for you , I wouldn't tell you . \n",
            " You've got to go . \n",
            "Have you heard about America's unemployment problem ? \n",
            " Yes , it has been steadily rising for many years . \n",
            " I've heard that Americans have a high rate of unemployment . \n",
            " What does it mean ? \n",
            " The American dream is to have a job and have a family , but unemployment is not the only responsibility that comes with it . \n",
            " Really ? \n",
            " I\n",
            "I'm fuming ! \n",
            " What ? But I have a baby . \n",
            " My mind is on it . \n",
            " How can you say that ? \n",
            " You don't know what you're talking about . I know I've been out of work since 7 , and I ’ m getting laid off.So you're going crazy ? \n",
            " Yeah , I mean , I'm freaking out . What am I supposed to do ? \n",
            " I'm just gonna take care of my kids , and I don't care if my\n",
            "Why am I always so angry ? \n",
            " I always feel terrible , but I've always been bright and energetic . \n",
            " What's so special about you ? \n",
            " I want you to be my new teacher . \n",
            " I'd like to come to school every day . \n",
            "How are you doing ? \n",
            " I'm fine . \n",
            " What are you up to ? \n",
            " I ’ Ve got a dance and I'm studying physics . \n",
            " Is that true ? \n",
            " Yes , I ’ m learning . \n",
            "\n",
            "I'm outraged ! \n",
            " What's wrong with you ? \n",
            " I was so upset yesterday . \n",
            " You're such a greedy American . \n",
            " I'm sorry , but you need to go back to school . \n",
            " Fine . \n",
            "Can you tell me how to get there ? \n",
            " Take the metro . \n",
            " Is there any highway left ? \n",
            " No.How about going to the police station at the next stop ? \n",
            " Why don't you go to the National Bank ? \n",
            " What about the\n",
            "That's gross ! \n",
            " What are you talking about ? It's the most disgusting , disgusting thing I've ever seen in my life ! \n",
            " Yeah . I think we should clean the room . \n",
            " I know , but it's really very disgusting at the same time . \n",
            "Excuse me . What should I do next ? \n",
            " Will you please take a look at this map ? \n",
            " Here it is . \n",
            " It ’ s all over the map . \n",
            " Could I go back to it later\n",
            "I'm disgusted . \n",
            " I know . \n",
            " I've heard about all kinds of things . I believe in love . \n",
            " Why are you so angry about it ? \n",
            " I don't know . \n",
            " What do you mean ? \n",
            " I'm not mad . \n",
            "Are you free on Saturday or Sunday ? \n",
            " I'll be there tomorrow . \n",
            " That's perfect . \n",
            " Let's go . \n",
            "Excuse me , is this the bus leaving in ten minutes ? \n",
            " No.This\n",
            "Ew ,  that's nasty ! \n",
            " Well , let me see ... you're a free man ! \n",
            " Well , let's call it a day . \n",
            " Good idea . Let's go back and finish this ! \n",
            " Why ? \n",
            " It's a holiday , isn't it ? \n",
            " What time is it ? \n",
            " It's Saturday . \n",
            " Ok , let's finish that . \n",
            " Hey ! Don't do anything silly ! \n",
            "Hey , Tom , what ’ s up ? \n",
            " Nothing , thanks\n",
            "This is repulsive . \n",
            " Yes . It's unbelievable . \n",
            "Hello , Tom . This is Bill . Good morning . What can I help you ? \n",
            " Hi , Daniel . I am waiting for a package . \n",
            " Is there anything I can help you with ? \n",
            " Yes , what kind of package would you like ? \n",
            " I have a package for my daughter . \n",
            " Do you have a package ? \n",
            " No , I do not . \n",
            " What's the price , Daniel ? \n",
            " It's\n",
            "I can't stand this . \n",
            " Oh , I can't . \n",
            " You should stop . You're getting married too soon . \n",
            " Yes , I can't stand you . \n",
            " You're a beautiful woman . \n",
            " I envy you . \n",
            " I'd better stop . \n",
            "You ’ re such a grown-up . \n",
            " I ’ m not , I ’ m just a baby . \n",
            " But you look so young and strong . \n",
            " Mom , I always look young and healthy . \n",
            "I'm scared . \n",
            " Don't worry . \n",
            " Are you sure ? \n",
            " Yeah . I'm sure . I just really have no idea . \n",
            " Why don't we have a meeting this afternoon ? \n",
            " I think it's a good opportunity to talk about the management and work relationship . \n",
            " OK . Let's take a look at the slides . \n",
            " Here you go ! What are they about ? \n",
            " They're a couple of documents making a decision about management . \n",
            " Which documents do they say\n",
            "This is terrifying . \n",
            "Hi , how are you ? \n",
            " Fine . I ’ m feeling better . \n",
            " And how are you doing ? \n",
            " Great . I ’ m feeling better too . I ’ Ve had a little trouble sleeping . \n",
            " Oh , what a shame ! \n",
            " Well , I ’ m not feeling well . I had a little trouble getting up , so I ’ Ve been having headaches and a headache myself . Oh , go ahead and stay asleep for a couple of hours\n",
            "I feel afraid . \n",
            " As a matter of fact , I've been feeling quite good lately . \n",
            " What do you think about it ? \n",
            " I feel better now . \n",
            " If something's bothering you , just leave me an email . \n",
            " Thank you . \n",
            "Have you noticed how handsome you are ? \n",
            " Yes , I've seen you in public places . \n",
            " I'm too small ! \n",
            " I can wear a lot of clothes . \n",
            " I think you're smart . \n",
            " I envy\n",
            "I'm really frightened . \n",
            " How long have you been feeling this way ? \n",
            " I haven't been feeling it for two weeks . I think I'm overreacting . I'm really worried . \n",
            " I guess you're right . I'm trying to sleep now . \n",
            " It's a bit difficult . I find it hard to concentrate . \n",
            " We're trying to make up to you . \n",
            " I feel awful . \n",
            "I don't know if we can get on with this . \n",
            " Let's try\n",
            "This is spooky . \n",
            " Why bother ? \n",
            " It's not crazy . \n",
            " I heard the story , Mr . Simpson . He used to work for the newspaper . \n",
            " Maybe he doesn't tell us anything . \n",
            " You bet ! \n",
            " He's very nice to me . \n",
            " Well , it's time for me to step away . \n",
            " I don't mind if you wait and see . \n",
            "Excuse me , would you please come in ? \n",
            " I want to check out the place for\n",
            "I'm so happy ! \n",
            " Thank you for inviting me . \n",
            " I'll be here in a minute . Can I help you ? \n",
            " Sure . Here you are . \n",
            "I'm glad we have found a place to live . \n",
            " Yes , I have . \n",
            " Could you come over and have a look ? \n",
            " Sure , I'd like to . \n",
            " Where would you like to live ? \n",
            " I'd like to live in a small apartment . \n",
            " Let's see . Will you help me\n",
            "This is awesome ! \n",
            " I'll use it on one of the chairs next time . \n",
            "I am so glad to hear that . \n",
            " When can I expect you to arrive ? \n",
            " I am planning to visit your sister in Beijing sometime next month . \n",
            "May I have the guestbook of your meeting ? \n",
            " Sir , I am glad to meet you . In the meantime , I'd like to send you an informal invitation . \n",
            " OK . Please give me a call sometime next week . \n",
            " Thank\n",
            "I'm delighted . \n",
            " OK . Do you want to go with me ? \n",
            " We'll go next to the club next Thursday . \n",
            " What time is it ? \n",
            " We'll be waiting for you then . \n",
            "Good morning , sir . I ’ m sorry to have brought you this wrong item . \n",
            " Thank you , sir . I would like to order a hamburger . \n",
            " Can you give me directions as to where it ’ s located ? \n",
            " Yes , please . Here ' s\n",
            "Yay ,  I'm so glad ! \n",
            "Hi , Mary ! How nice to meet you . \n",
            " Thanks , Mary . I ’ Ve decided to go to a movie with you . \n",
            " I ’ Ve seen the movie and I ’ m really excited about it ! \n",
            " I like the music . I ’ Ve got to go and see it . \n",
            " Look , I ’ Ve got to go and see it . \n",
            "Hi , Mary ! When do you come back ? \n",
            " By my birthday . \n",
            "This makes me smile . \n",
            " You're right . You look beautiful . \n",
            " Yes . I'm glad to see you again . \n",
            "May I help you ? \n",
            " Yes , I'm looking for a room with a view , please . \n",
            " How long would you like to stay ? \n",
            " About 5 nights . \n",
            " Do you have a reservation ? \n",
            " Yes . \n",
            "How would you like to go to the library ? \n",
            " I've got to get to the library at 7 . \n",
            " 7 a\n",
            "I'm feeling sad . \n",
            " Yes , I'm feeling depressed . \n",
            " Did you sleep well yesterday ? \n",
            " Actually , I feel a lot better today . \n",
            " Oh , no , I didn't sleep well . \n",
            " Oh , no , I'm too tired to sleep . \n",
            " Maybe you should try something else . \n",
            "Hi , Jill . How are you ? \n",
            " Great . I feel good . What can I do for you ? \n",
            " I'm getting ready for vacation . \n",
            " What is it about\n",
            "This is so upsetting . \n",
            " I am sorry that you have no choice . \n",
            " I'm sorry to hear that . \n",
            " I understand . Here's your apology and I will make it to you by tomorrow afternoon . \n",
            "Would you like anything else ? \n",
            " Yes , I'd like a cup of coffee , please . \n",
            " Please fill in the form . \n",
            " OK . Let me check if you'd like any special items . \n",
            " Could I bring a briefcase with you ? \n",
            " A briefcase with\n",
            "I'm really down . \n",
            " That's not fair . He put me in a sticky position . \n",
            " Make up your mind . \n",
            "Hi , Mary . Nice to meet you . \n",
            " Hi , Joe . \n",
            " Hi , Alice . Nice to meet you too . \n",
            " Nice to meet you too . \n",
            " Nice to meet you too . \n",
            " Nice to meet you too . \n",
            " Nice to meet you too . \n",
            " OK , Joe . Nice to meet you too . \n",
            "Good afternoon , Steven .\n",
            "Why am I so sad ? \n",
            " Well , I totally bought her the hat . \n",
            " Don't be so negative . You just let go of her . \n",
            "Have you got any ideas on what kind of action to take ? \n",
            " I think I ’ ll take some action . \n",
            " What would you like to do ? \n",
            " I ’ d like to go to my home . \n",
            " I ’ m sorry , but it ’ s not taking far . \n",
            " How about going to the gym ? \n",
            "This makes me gloomy . \n",
            " I ’ m not sure . \n",
            "I want to buy a motorcycle . \n",
            " What kind of motorcycle do you want ? \n",
            " Honda motorcycle . \n",
            " What kind of motorcycle do you want ? \n",
            " I want to have a motorcycle . \n",
            " What kind of motorcycle must we buy ? \n",
            " I want to have a motorcycle that suits my needs , so I don't have to worry about it . \n",
            " What are you looking for ? \n",
            " Well , Honda motorcycle , maybe something\n",
            "Wow ,  that's surprising ! \n",
            " Your age is 42 . Does it matter if I'm younger or younger ? \n",
            " It's just that I'm very young . \n",
            " So what did you have to learn ? \n",
            " I think I learned a lot . I learned to fly . \n",
            " Really ? Tell me about it . \n",
            " They used to fly every weekend . \n",
            " A lot of people have been flying together . \n",
            " Then how did you learn to fly ? \n",
            " I learned to fly when I was in high\n",
            "I didn't expect this . \n",
            " You're lucky . \n",
            "I like to watch sports . \n",
            " I like to watch football , too . \n",
            " What sports do you like ? \n",
            " Basketball and rugby . \n",
            " How do you like them ? \n",
            " They are fun . \n",
            " Don't worry . They don't even have to be played , though . \n",
            " That's good . \n",
            "My Santa gave me an amazing bag ! \n",
            " What a surprise ! \n",
            " It was my birthday present . \n",
            " Thank\n",
            "This is shocking ! \n",
            " I was on my way to get a table with my family when it was first announced that all of our guests would be getting a part-time job on campus . \n",
            " How did you know that ? \n",
            " I thought it was my idea to have lunch with my family . \n",
            " I think the dinner would be great for our family . \n",
            " Good idea ! And the whole family would come together to have a great time together ! \n",
            "Hi Linda , what can I do for you ?\n",
            "Really ?  That's unexpected . \n",
            " I don't like it . It's too loud , too . \n",
            "It's freezing outside . \n",
            " It's getting late . \n",
            " Don't worry . I'll be back soon . \n",
            " Thanks , but I've lost my wallet . \n",
            " You could have picked me up somewhere . \n",
            " Well , I'm glad you asked . \n",
            " I'm glad you didn't . \n",
            " I just remember . \n",
            "What ’ s wrong with you ? \n",
            " I ’\n",
            "I'm amazed by this ! \n",
            "Hello ! Would you like to help me ? \n",
            " How may I help you ? \n",
            " I would like to buy some wool clothes . What kind of clothes should I get ? \n",
            " What kind of fleece ? \n",
            " I would like it made of 100 % wool and 100 % cotton . \n",
            " That's too expensive . Would you give me a ring for this ? \n",
            " Of course ! \n",
            "I want to make a diamond ring . \n",
            " What color do you want ? \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d28c2be3be440369896f6a6833effc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57897c18d9ac433e9952ac9435a273f1",
              "IPY_MODEL_78ea2735a8a44a8d8aaed5a7cb5f93f5",
              "IPY_MODEL_c5896e1d58c24088aaf39a19d9ed28d7"
            ],
            "layout": "IPY_MODEL_ae8a37d495b94e51913d50136d9984ca"
          }
        },
        "57897c18d9ac433e9952ac9435a273f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a6dd6616094f0aa7330262feec2771",
            "placeholder": "​",
            "style": "IPY_MODEL_0ec6deeb509a47feb486f38a33a04937",
            "value": "config.json: 100%"
          }
        },
        "78ea2735a8a44a8d8aaed5a7cb5f93f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2bbbc9d05434c928574de20e56026b3",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_722756905fa149aea2da642052e630f4",
            "value": 665
          }
        },
        "c5896e1d58c24088aaf39a19d9ed28d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5388a7ddd8964a0490ddf8175918687c",
            "placeholder": "​",
            "style": "IPY_MODEL_b5d13564055c43f7a8e267842612898f",
            "value": " 665/665 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "ae8a37d495b94e51913d50136d9984ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a6dd6616094f0aa7330262feec2771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ec6deeb509a47feb486f38a33a04937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2bbbc9d05434c928574de20e56026b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "722756905fa149aea2da642052e630f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5388a7ddd8964a0490ddf8175918687c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d13564055c43f7a8e267842612898f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b1c8ccac3f04307b9d7587eec5b7373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff253d52ee354a3098d9d43418735038",
              "IPY_MODEL_ad5db893ff954d06a8362fdbf5d2c74e",
              "IPY_MODEL_0d82a880321d4af6be3a21da6669666c"
            ],
            "layout": "IPY_MODEL_91e73ec8c9c54b588ffdab77edb3b43c"
          }
        },
        "ff253d52ee354a3098d9d43418735038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5afed84ace84e4c8b0caf79b62f07c7",
            "placeholder": "​",
            "style": "IPY_MODEL_7903f91b370d4ffbb38c31f9482afb7e",
            "value": "model.safetensors: 100%"
          }
        },
        "ad5db893ff954d06a8362fdbf5d2c74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091448e47eca4138b450b359db020574",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ca23c5b51764ef7a3296fe33695adcb",
            "value": 548105171
          }
        },
        "0d82a880321d4af6be3a21da6669666c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c6aefe3ffb4509a967ab5c36694afa",
            "placeholder": "​",
            "style": "IPY_MODEL_48a3f1ef4cee4b2d998850b9d46b0895",
            "value": " 548M/548M [00:05&lt;00:00, 135MB/s]"
          }
        },
        "91e73ec8c9c54b588ffdab77edb3b43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5afed84ace84e4c8b0caf79b62f07c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7903f91b370d4ffbb38c31f9482afb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "091448e47eca4138b450b359db020574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ca23c5b51764ef7a3296fe33695adcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18c6aefe3ffb4509a967ab5c36694afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a3f1ef4cee4b2d998850b9d46b0895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6831af991f644849b0cc4d8e01a2f1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae6dba01553c4e5ea07bd3476278cd24",
              "IPY_MODEL_933c5efa45c5410e8eb45bd99a7889fc",
              "IPY_MODEL_dbc6f9a18e6244afa0257617283db2cb"
            ],
            "layout": "IPY_MODEL_af54237dfd10456382f426ef316b2643"
          }
        },
        "ae6dba01553c4e5ea07bd3476278cd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62e0f13b8ee41bf99bb608d8b4475c8",
            "placeholder": "​",
            "style": "IPY_MODEL_c03b6287b1dd48e9ab3f687c4b1efe07",
            "value": "generation_config.json: 100%"
          }
        },
        "933c5efa45c5410e8eb45bd99a7889fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e0369bf57b4994a599c9b7fbffcd48",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c9643d5891d499db4daebc76278d19f",
            "value": 124
          }
        },
        "dbc6f9a18e6244afa0257617283db2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c264fd995fdc4aa2910568c0f2e8d219",
            "placeholder": "​",
            "style": "IPY_MODEL_c9c134ca3b27491e91eee7910fe40bfa",
            "value": " 124/124 [00:00&lt;00:00, 3.07kB/s]"
          }
        },
        "af54237dfd10456382f426ef316b2643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62e0f13b8ee41bf99bb608d8b4475c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03b6287b1dd48e9ab3f687c4b1efe07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46e0369bf57b4994a599c9b7fbffcd48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9643d5891d499db4daebc76278d19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c264fd995fdc4aa2910568c0f2e8d219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c134ca3b27491e91eee7910fe40bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}